{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7PDdLv6cTc6kMTTul/T2k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hargagan/EDA-NYC-Taxi-Data-Analysis/blob/main/pyspark/C3_M2_Practice_exercise_assgnmnt_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f8nWOf0XPqyY"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('chipotle').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B2hj740P6QL",
        "outputId": "4c799f47-a098-4f3f-9f4c-12d6b7a2a651"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_chipotle = spark.read.csv('/content/drive/MyDrive/Assignments/EDA/chipotle (1).tsv', sep='\\t', header=True)"
      ],
      "metadata": {
        "id": "ZfNJKnZ2QBfy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_chipotle.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJn_fRbjQS46",
        "outputId": "e8436b05-f603-49ee-dba0-936d343dab7d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------------------+--------------------+----------+\n",
            "|order_id|quantity|           item_name|  choice_description|item_price|\n",
            "+--------+--------+--------------------+--------------------+----------+\n",
            "|       1|       1|Chips and Fresh T...|                NULL|    $2.39 |\n",
            "|       1|       1|                Izze|        [Clementine]|    $3.39 |\n",
            "|       1|       1|    Nantucket Nectar|             [Apple]|    $3.39 |\n",
            "|       1|       1|Chips and Tomatil...|                NULL|    $2.39 |\n",
            "|       2|       2|        Chicken Bowl|[Tomatillo-Red Ch...|   $16.98 |\n",
            "+--------+--------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Task 1:** Write a function that returns the total revenue generated from all orders. Hint: Multiply quantity by item_price for each row and then add the results."
      ],
      "metadata": {
        "id": "s6HbfEhKQhXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_revenue(df):\n",
        "    from pyspark.sql.functions import udf, regexp_replace, trim\n",
        "    from pyspark.sql.types import FloatType\n",
        "    # Remove '$' and trim spaces before casting to float\n",
        "    df = df.withColumn('item_price', trim(regexp_replace(df['item_price'], '\\\\$', '')).cast('float'))\n",
        "    df = df.withColumn('revenue', df['quantity'] * df['item_price'])\n",
        "    return df.agg({'revenue': 'sum'}).collect()[0][0]\n",
        "\n",
        "get_total_revenue(df_chipotle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLH6dRfIQmoh",
        "outputId": "9f85377d-1e85-4e79-c103-dac40d2402e4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39237.01973223686"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 2:** Write a function that returns the most frequently ordered item. Hint: Group by item_name and sum the quantity."
      ],
      "metadata": {
        "id": "-ADTme41Rd-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_ordered_item(df):\n",
        "    from pyspark.sql.functions import sum\n",
        "    return df.groupBy('item_name').agg(sum('quantity').alias('total_quantity')).orderBy('total_quantity', ascending=False).first()\n",
        "\n",
        "\n",
        "get_most_ordered_item(df_chipotle)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fd_RYucRg4r",
        "outputId": "3b245a70-ee49-453f-8ee3-d1b8947f1845"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(item_name='Chicken Bowl', total_quantity=761.0)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 3:** Write a function that returns the total number of unique items sold. Hint: Count the number of distinct values in the item_name column."
      ],
      "metadata": {
        "id": "BGS3UThuSAys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_distinct_items(df):\n",
        "    return df.select('item_name').distinct().count()\n",
        "\n",
        "count_distinct_items(df_chipotle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2LoVdfiSEU7",
        "outputId": "51b453c7-625b-4d58-f24d-c7f74acfc2ce"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 4:** Write a function that returns the top 5 items by total revenue. Hint: Multiply quantity and item_price, group by item_name, and sort in descending order."
      ],
      "metadata": {
        "id": "0K9dJnw3STIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_5_items_by_revenue(df):\n",
        "    from pyspark.sql.functions import regexp_replace, trim\n",
        "\n",
        "    df = df.withColumn('item_price', trim(regexp_replace(df['item_price'], '\\\\$', '')).cast('float'))\n",
        "    df = df.withColumn('revenue', df['quantity'] * df['item_price'])\n",
        "    df.createOrReplaceTempView('chipotle')\n",
        "    return spark.sql(\"\"\"\n",
        "        SELECT item_name, SUM(revenue) AS total_revenue\n",
        "        FROM chipotle\n",
        "        GROUP BY item_name\n",
        "        ORDER BY total_revenue DESC\n",
        "        LIMIT 5\n",
        "    \"\"\")\n",
        "\n",
        "get_top_5_items_by_revenue(df_chipotle).show()\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFetZjRGSSrq",
        "outputId": "02e8ed63-6d79-4397-d9d3-ff9d122bc067"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------------------+\n",
            "|          item_name|     total_revenue|\n",
            "+-------------------+------------------+\n",
            "|       Chicken Bowl|8044.6299295425415|\n",
            "|    Chicken Burrito| 6387.059944152832|\n",
            "|      Steak Burrito| 4236.129955291748|\n",
            "|         Steak Bowl|2479.8099822998047|\n",
            "|Chips and Guacamole| 2475.619917869568|\n",
            "+-------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 5:** Write a function that returns the average number of items per order. Hint: Group by order_id, sum the quantity per order, and calculate the mean."
      ],
      "metadata": {
        "id": "tBPlkxJOTNDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_average_items_per_order(df):\n",
        "    from pyspark.sql.functions import avg\n",
        "    df.createOrReplaceTempView('chipotle')\n",
        "    return spark.sql(\"\"\"\n",
        "        SELECT AVG(total_quantity) AS avg_items_per_order\n",
        "        FROM (\n",
        "            SELECT order_id, SUM(quantity) AS total_quantity\n",
        "            FROM chipotle\n",
        "            GROUP BY order_id\n",
        "        ) AS order_quantities\n",
        "    \"\"\").collect()[0][0]\n",
        "\n",
        "get_average_items_per_order(df_chipotle)\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE59H3NKTQaZ",
        "outputId": "4c8ca33a-d658-442e-d5f5-9b94a844adba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.711014176663032"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 6:** List all beverages sold and their total revenue."
      ],
      "metadata": {
        "id": "IQ_-dFKaTu89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_beverages_and_revenue(df):\n",
        "  from pyspark.sql.functions import regexp_replace, trim, sum, round\n",
        "  df = df.withColumn('item_price', trim(regexp_replace(df['item_price'], '\\\\$', '')).cast('float'))\n",
        "  df = df.withColumn('revenue', df['quantity'] * df['item_price'])\n",
        "  return df.filter(df['item_name'].isin(['6 Pack Soft Drink', 'Canned Soft Drink', 'Izze'])).groupBy('item_name').agg(round(sum('revenue'), 2).alias('total_revenue')).show()\n",
        "\n",
        "list_beverages_and_revenue(df_chipotle)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNCaQtCwTw_-",
        "outputId": "5d60afa9-7041-48a3-85c8-b229a8c07b1b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|        item_name|total_revenue|\n",
            "+-----------------+-------------+\n",
            "|6 Pack Soft Drink|       369.93|\n",
            "|Canned Soft Drink|       603.75|\n",
            "|             Izze|         67.8|\n",
            "+-----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}