{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1AwZAMmSC80ODSqV15jNy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hargagan/EDA-NYC-Taxi-Data-Analysis/blob/main/pyspark/C3_M2_Practice_exercise_assgnmnt_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-qkYzfRrWDg-"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName('AIAdoptionAndWorkforceImpactData').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXrKyg8aWhTr",
        "outputId": "7bc768ae-80dc-4753-aa9b-c2a5ae4c359d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ai = spark.read.csv('/content/drive/MyDrive/Assignments/EDA/Enterprise_GenAI_Adoption_Impact.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "TWQGYmKhW6ev"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ai.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB60_4FHXGB9",
        "outputId": "ecb3c243-8c2a-4ee2-8d16-634c9684d484"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Company Name: string (nullable = true)\n",
            " |-- Industry: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- GenAI Tool: string (nullable = true)\n",
            " |-- Adoption Year: integer (nullable = true)\n",
            " |-- Number of Employees Impacted: integer (nullable = true)\n",
            " |-- New Roles Created: integer (nullable = true)\n",
            " |-- Training Hours Provided: integer (nullable = true)\n",
            " |-- Productivity Change (%): double (nullable = true)\n",
            " |-- Employee Sentiment: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ai.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OjHkgOXXNmI",
        "outputId": "a5974428-ced6-4f9c-ed31-c2b3c80567a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+------------+----------+-------------+----------------------------+-----------------+-----------------------+-----------------------+--------------------+\n",
            "|        Company Name|   Industry|     Country|GenAI Tool|Adoption Year|Number of Employees Impacted|New Roles Created|Training Hours Provided|Productivity Change (%)|  Employee Sentiment|\n",
            "+--------------------+-----------+------------+----------+-------------+----------------------------+-----------------+-----------------------+-----------------------+--------------------+\n",
            "| Davis LLC Pvt. Ltd.| Healthcare|         USA|   Mixtral|         2022|                        5277|                8|                    657|                   25.2|Productivity incr...|\n",
            "|Roberts, Holland ...|    Telecom|South Africa|    Claude|         2023|                       18762|               17|                  23021|                   27.5|We now finish tas...|\n",
            "| Roman Inc Pvt. Ltd.|Advertising|       India|    Gemini|         2023|                       11307|               17|                   4680|                   11.5|Productivity incr...|\n",
            "|Nguyen-Strickland...| Technology|          UK|      Groq|         2023|                       18834|               12|                   1750|                    7.0|AI helped me redu...|\n",
            "|Jackson PLC Pvt. ...|Hospitality|          UK|     LLaMA|         2024|                        8364|               22|                   3925|                    2.5|Job roles have sh...|\n",
            "+--------------------+-----------+------------+----------+-------------+----------------------------+-----------------+-----------------------+-----------------------+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 1:** Write a function that returns the number of rows, the number of columns, the list of unique GenAI tools used and the number of distinct industries in the dataset."
      ],
      "metadata": {
        "id": "dM2efqkgXZMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def row_col_genai_count_distinct_industry(df):\n",
        "    num_rows = df.count()\n",
        "    num_cols = len(df.columns)\n",
        "    unique_genai_tools = df.select('GenAI Tool').distinct().rdd.flatMap(lambda x: x).collect()\n",
        "    num_distinct_industries = df.select('Industry').distinct().count()\n",
        "    return num_rows, num_cols, unique_genai_tools, num_distinct_industries\n",
        "\n",
        "row_col_genai_count_distinct_industry(df_ai)\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymGnfpUPXYZ4",
        "outputId": "2af4660c-146b-473e-9949-1c800aa6ebe7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 10, ['ChatGPT', 'Gemini', 'LLaMA', 'Claude', 'Groq', 'Mixtral'], 14)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 2:** Write a function that standardises column names by converting them to lowercase and replacing spaces with underscores."
      ],
      "metadata": {
        "id": "ylcHn-lmYeh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_column_names(df):\n",
        "    new_column_names = [col.lower().replace(\" \", \"_\") for col in df.columns]\n",
        "    df = df.toDF(*new_column_names)\n",
        "    return df\n",
        "\n",
        "df_ai = standardize_column_names(df_ai)\n",
        "df_ai.printSchema()\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwzngYtDYiK7",
        "outputId": "c3fbcf2c-e937-42b7-c1ea-7dffb26e016f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- company_name: string (nullable = true)\n",
            " |-- industry: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- genai_tool: string (nullable = true)\n",
            " |-- adoption_year: integer (nullable = true)\n",
            " |-- number_of_employees_impacted: integer (nullable = true)\n",
            " |-- new_roles_created: integer (nullable = true)\n",
            " |-- training_hours_provided: integer (nullable = true)\n",
            " |-- productivity_change_(%): double (nullable = true)\n",
            " |-- employee_sentiment: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 3:** Write a function that returns a dictionary with column names as keys and a count of null or missing values as values."
      ],
      "metadata": {
        "id": "2LiUF_QdY87v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def count_null_values_or_missing_values(df):\n",
        "    null_or_missing_counts = {}\n",
        "    for col_name, col_type in df.dtypes:\n",
        "        # Count explicit nulls\n",
        "        null_count = df.filter(df[col_name].isNull()).count()\n",
        "        missing_value_count = 0\n",
        "        # If the column is a string type, also check for empty strings\n",
        "        if col_type == 'string':\n",
        "            missing_value_count = df.filter(df[col_name] == '').count()\n",
        "        null_or_missing_counts[col_name] = null_count + missing_value_count\n",
        "    return null_or_missing_counts\n",
        "\n",
        "count_null_values_or_missing_values(df_ai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5_xV3bNY806",
        "outputId": "17a09d91-f300-4c4a-a7dc-944a2d39f783"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'company_name': 0,\n",
              " 'industry': 0,\n",
              " 'country': 0,\n",
              " 'genai_tool': 0,\n",
              " 'adoption_year': 0,\n",
              " 'number_of_employees_impacted': 0,\n",
              " 'new_roles_created': 0,\n",
              " 'training_hours_provided': 0,\n",
              " 'productivity_change_(%)': 0,\n",
              " 'employee_sentiment': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 4:** Write a function that casts adoption_year to IntegerType, productivity_change to FloatType and training_hours_provided and number_of_employees_impacted to IntegerType."
      ],
      "metadata": {
        "id": "aa87eZI4ZzF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cast_adoptions_year_productivity_change_training_hours_number_of_employees(df):\n",
        "    df = df.withColumn(\"adoption_year\", df[\"adoption_year\"].cast(\"integer\"))\n",
        "    df = df.withColumn(\"productivity_change_(%)\", df[\"productivity_change_(%)\"].cast(\"float\"))\n",
        "    df = df.withColumn(\"training_hours_provided\", df[\"training_hours_provided\"].cast(\"integer\"))\n",
        "    df = df.withColumn(\"number_of_employees_impacted\", df[\"number_of_employees_impacted\"].cast(\"integer\"))\n",
        "    return df\n",
        "\n",
        "df_ai = cast_adoptions_year_productivity_change_training_hours_number_of_employees(df_ai)\n",
        "df_ai.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEDdNXA5Z4AN",
        "outputId": "8250327b-1e93-4320-e8e8-5f839260fd93"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- company_name: string (nullable = true)\n",
            " |-- industry: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- genai_tool: string (nullable = true)\n",
            " |-- adoption_year: integer (nullable = true)\n",
            " |-- number_of_employees_impacted: integer (nullable = true)\n",
            " |-- new_roles_created: integer (nullable = true)\n",
            " |-- training_hours_provided: integer (nullable = true)\n",
            " |-- productivity_change_(%): float (nullable = true)\n",
            " |-- employee_sentiment: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 5:** Write a function that adds a new column adoption_level based on number_of_employees_impacted: High if >5000, medium if 1000â€“5000 and low if <1000."
      ],
      "metadata": {
        "id": "fhv1SNBKbCvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def new_column_based_on_number_of_employees(df):\n",
        "  from pyspark.sql.functions import when\n",
        "  df = df.withColumn(\"adoption_level\",\n",
        "                     when(df[\"number_of_employees_impacted\"] > 5000, \"High\")\n",
        "                     .when((df[\"number_of_employees_impacted\"] >= 1000) &\n",
        "                           (df[\"number_of_employees_impacted\"] <= 5000), \"Medium\")\n",
        "                     .otherwise(\"Low\"))\n",
        "  return df\n",
        "\n",
        "df_ai = new_column_based_on_number_of_employees(df_ai)\n",
        "df_ai.printSchema()\n",
        "df_ai.show(5)\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbPHNuAybFgO",
        "outputId": "862b05b5-5854-4114-dbf8-f95edce3a0b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- company_name: string (nullable = true)\n",
            " |-- industry: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- genai_tool: string (nullable = true)\n",
            " |-- adoption_year: integer (nullable = true)\n",
            " |-- number_of_employees_impacted: integer (nullable = true)\n",
            " |-- new_roles_created: integer (nullable = true)\n",
            " |-- training_hours_provided: integer (nullable = true)\n",
            " |-- productivity_change_(%): float (nullable = true)\n",
            " |-- employee_sentiment: string (nullable = true)\n",
            " |-- adoption_level: string (nullable = false)\n",
            "\n",
            "+--------------------+-----------+------------+----------+-------------+----------------------------+-----------------+-----------------------+-----------------------+--------------------+--------------+\n",
            "|        company_name|   industry|     country|genai_tool|adoption_year|number_of_employees_impacted|new_roles_created|training_hours_provided|productivity_change_(%)|  employee_sentiment|adoption_level|\n",
            "+--------------------+-----------+------------+----------+-------------+----------------------------+-----------------+-----------------------+-----------------------+--------------------+--------------+\n",
            "| Davis LLC Pvt. Ltd.| Healthcare|         USA|   Mixtral|         2022|                        5277|                8|                    657|                   25.2|Productivity incr...|          High|\n",
            "|Roberts, Holland ...|    Telecom|South Africa|    Claude|         2023|                       18762|               17|                  23021|                   27.5|We now finish tas...|          High|\n",
            "| Roman Inc Pvt. Ltd.|Advertising|       India|    Gemini|         2023|                       11307|               17|                   4680|                   11.5|Productivity incr...|          High|\n",
            "|Nguyen-Strickland...| Technology|          UK|      Groq|         2023|                       18834|               12|                   1750|                    7.0|AI helped me redu...|          High|\n",
            "|Jackson PLC Pvt. ...|Hospitality|          UK|     LLaMA|         2024|                        8364|               22|                   3925|                    2.5|Job roles have sh...|          High|\n",
            "+--------------------+-----------+------------+----------+-------------+----------------------------+-----------------+-----------------------+-----------------------+--------------------+--------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 6:** Write a function that groups the dataset by country and industry, and returns the total number of companies, average productivity change and total new roles created."
      ],
      "metadata": {
        "id": "Rp35byP4bpV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def group_by_country_industry(df):\n",
        "  import pyspark.sql.functions as F\n",
        "  from pyspark.sql.functions import count, avg, sum\n",
        "  df.groupBy(\"country\", \"industry\").agg(\n",
        "      count(\"company_name\").alias(\"total_companies\"),\n",
        "      avg(\"productivity_change_(%)\").alias(\"average_productivity_change\"),\n",
        "      sum(\"new_roles_created\").alias(\"total_new_roles_created\")).orderBy(\"country\", \"industry\").show()\n",
        "\n",
        "group_by_country_industry(df_ai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feokA7k1baoW",
        "outputId": "b7be0a6c-6dba-4a96-bf4f-c9e4c1e9efad"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------+---------------+---------------------------+-----------------------+\n",
            "|  country|      industry|total_companies|average_productivity_change|total_new_roles_created|\n",
            "+---------+--------------+---------------+---------------------------+-----------------------+\n",
            "|Australia|   Advertising|            543|          17.95580110277699|                   8367|\n",
            "|Australia|       Defense|            533|         18.787804839311352|                   8141|\n",
            "|Australia|     Education|            495|         18.427474761250043|                   7513|\n",
            "|Australia| Entertainment|            535|          18.77738320003046|                   8546|\n",
            "|Australia|       Finance|            497|          18.90020121559051|                   7875|\n",
            "|Australia|    Healthcare|            550|          18.73709089756012|                   8417|\n",
            "|Australia|   Hospitality|            528|         18.695075743126147|                   8207|\n",
            "|Australia|Legal Services|            528|         18.626136363004193|                   8130|\n",
            "|Australia| Manufacturing|            525|         18.296761887414114|                   8240|\n",
            "|Australia|        Retail|            509|         18.053438105611296|                   7870|\n",
            "|Australia|    Technology|            536|          18.04402984923391|                   8084|\n",
            "|Australia|       Telecom|            481|          18.12557169057723|                   7321|\n",
            "|Australia|Transportation|            496|         18.526814522762454|                   7767|\n",
            "|Australia|     Utilities|            499|         17.792785562350897|                   7692|\n",
            "|   Brazil|   Advertising|            563|          18.73516873822119|                   8671|\n",
            "|   Brazil|       Defense|            532|          18.99680453762972|                   8660|\n",
            "|   Brazil|     Education|            537|         18.544320270335874|                   8216|\n",
            "|   Brazil| Entertainment|            517|         18.386460352220663|                   7964|\n",
            "|   Brazil|       Finance|            509|           18.9874263577939|                   7807|\n",
            "|   Brazil|    Healthcare|            553|          18.20415912010786|                   8687|\n",
            "+---------+--------------+---------------+---------------------------+-----------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####**Task 7:** Write a function that preprocesses the employee_sentiment column by converting it to lowercase and removing punctuation."
      ],
      "metadata": {
        "id": "-gO6I2kgc0Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "def clean_employee_sentiment(df):\n",
        "  from pyspark.sql.functions import lower, regexp_replace\n",
        "  df = df.withColumn(\"employee_sentiment\", lower(df[\"employee_sentiment\"]))\n",
        "  df = df.withColumn(\"employee_sentiment\", regexp_replace(df[\"employee_sentiment\"], \"[^a-zA-Z0-9\\\\s]\", \"\"))\n",
        "  return df\n",
        "\n",
        "df_ai = clean_employee_sentiment(df_ai)\n",
        "df_ai.select(F.col('employee_sentiment')).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkLL-yrYc3SF",
        "outputId": "9aabd9f6-0c28-40b9-c882-009b7f5f46b7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|  employee_sentiment|\n",
            "+--------------------+\n",
            "|productivity incr...|\n",
            "|we now finish tas...|\n",
            "|productivity incr...|\n",
            "|ai helped me redu...|\n",
            "|job roles have sh...|\n",
            "|new roles are exc...|\n",
            "|job roles have sh...|\n",
            "|collaboration imp...|\n",
            "|theres concern th...|\n",
            "|i love using aiit...|\n",
            "|job roles have sh...|\n",
            "|job roles have sh...|\n",
            "|job roles have sh...|\n",
            "|collaboration imp...|\n",
            "|ai helped me redu...|\n",
            "|collaboration imp...|\n",
            "|we now finish tas...|\n",
            "|theres concern th...|\n",
            "|productivity incr...|\n",
            "|theres concern th...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 8:** Write a function that returns a year-wise summary including number of companies, average training hours and the most adopted GenAI tool for each year."
      ],
      "metadata": {
        "id": "555UgFmadULv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def year_wise_summary(df):\n",
        "  import pyspark.sql.functions as F\n",
        "  from pyspark.sql.functions import count, avg\n",
        "  df.groupBy('adoption_year').agg(\n",
        "      count('company_name').alias('number_of_companies'),\n",
        "      avg('training_hours_provided').alias('average_training_hours'),\n",
        "      F.max('genai_tool').alias('most_adopted_genai_tool')).orderBy('adoption_year').show()\n",
        "\n",
        "year_wise_summary(df_ai)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeKgNy66dWi7",
        "outputId": "af46f2f2-627e-4af6-c210-eaac1d6f91f9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------------+----------------------+-----------------------+\n",
            "|adoption_year|number_of_companies|average_training_hours|most_adopted_genai_tool|\n",
            "+-------------+-------------------+----------------------+-----------------------+\n",
            "|         2022|              33180|    12797.869469559975|                Mixtral|\n",
            "|         2023|              33344|    12717.287817898272|                Mixtral|\n",
            "|         2024|              33476|    12712.635709164775|                Mixtral|\n",
            "+-------------+-------------------+----------------------+-----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 9:** Write a function that returns a cleaned version of the dataset with standardised column names, missing values handled, adoption_level column added and employee_sentiment trimmed to 100 characters."
      ],
      "metadata": {
        "id": "fpxfwmWBeL_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dataset(df):\n",
        "  df = standardize_column_names(df)\n",
        "  df = cast_adoptions_year_productivity_change_training_hours_number_of_employees(df)\n",
        "  df = new_column_based_on_number_of_employees(df)\n",
        "  df = clean_employee_sentiment(df)\n",
        "\n",
        "  df = df.withColumn(\"employee_sentiment\", F.substring(df[\"employee_sentiment\"], 1, 100))\n",
        "  return df\n",
        "\n",
        "df_ai = clean_dataset(df_ai)\n",
        "df_ai.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki3WnCcVeWVz",
        "outputId": "66d249f8-9e70-45eb-dae6-d951df18ffba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- company_name: string (nullable = true)\n",
            " |-- industry: string (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            " |-- genai_tool: string (nullable = true)\n",
            " |-- adoption_year: integer (nullable = true)\n",
            " |-- number_of_employees_impacted: integer (nullable = true)\n",
            " |-- new_roles_created: integer (nullable = true)\n",
            " |-- training_hours_provided: integer (nullable = true)\n",
            " |-- productivity_change_(%): float (nullable = true)\n",
            " |-- employee_sentiment: string (nullable = true)\n",
            " |-- adoption_level: string (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**Task 10:** Write a function that returns a star schema design with one fact table and three dimension tables: Company, time and genai_tool."
      ],
      "metadata": {
        "id": "XfSZ4o6Se5-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def star_schema_design(df):\n",
        "  df_company = df.select(\"company_name\", \"country\", \"industry\", \"number_of_employees_impacted\").distinct()\n",
        "  df_time = df.select(\"adoption_year\").distinct()\n",
        "  df_genai_tool = df.select(\"genai_tool\").distinct()\n",
        "  # The fact table should include measures and foreign keys to dimensions\n",
        "  df_fact_table = df.select(\n",
        "      \"company_name\",\n",
        "      \"adoption_year\",\n",
        "      \"genai_tool\",\n",
        "      \"productivity_change_(%)\",\n",
        "      \"adoption_level\",\n",
        "      \"training_hours_provided\",\n",
        "      \"new_roles_created\",\n",
        "      \"employee_sentiment\"\n",
        "  )\n",
        "\n",
        "  return df_company, df_time, df_genai_tool, df_fact_table\n",
        "\n",
        "df_company, df_time, df_genai_tool, df_fact_table = star_schema_design(df_ai)\n",
        "df_company.show()\n",
        "df_time.show()\n",
        "df_genai_tool.show()\n",
        "df_fact_table.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6sYSwyae814",
        "outputId": "a157ebc9-1742-4170-8aa1-3cf25a9ec9bf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+-------------+----------------------------+\n",
            "|        company_name|    country|     industry|number_of_employees_impacted|\n",
            "+--------------------+-----------+-------------+----------------------------+\n",
            "|Stafford-Collins ...|     France|      Finance|                        8236|\n",
            "|Miranda and Sons ...|        UAE|      Telecom|                       17832|\n",
            "|Williams Group Pv...|         UK|Manufacturing|                        6929|\n",
            "|Byrd-Patrick Pvt....|      India|    Education|                        4937|\n",
            "|Johnson, Ortiz an...|        USA|       Retail|                       17079|\n",
            "|Spencer-Johnson P...|     Canada|       Retail|                         591|\n",
            "|Robinson Ltd Pvt....|     France|Entertainment|                        4469|\n",
            "|Hanson, Gilbert a...|  Australia|    Utilities|                        9547|\n",
            "|Curry, Wilson and...|     Canada|   Healthcare|                         599|\n",
            "|Gallagher, Brown ...|    Germany|      Telecom|                       15408|\n",
            "|Smith, Thomas and...|  Singapore|      Finance|                       19688|\n",
            "|Davis, Jenkins an...|Switzerland|  Advertising|                       10460|\n",
            "|Jones, Mejia and ...|  Australia|   Healthcare|                        1445|\n",
            "|Morgan-Villa Pvt....|        USA|    Utilities|                       10525|\n",
            "|Mason, Johnson an...|         UK|      Telecom|                       14108|\n",
            "|Stephens, Garcia ...|        USA|      Telecom|                        8399|\n",
            "|Duke, Washington ...|  Singapore|       Retail|                       13241|\n",
            "|Wong-Gardner Pvt....|Switzerland|  Advertising|                       10469|\n",
            "|Jones, Peterson a...|        USA|Entertainment|                       14084|\n",
            "|Wilson-Dawson Pvt...|Switzerland|    Education|                        7230|\n",
            "+--------------------+-----------+-------------+----------------------------+\n",
            "only showing top 20 rows\n",
            "+-------------+\n",
            "|adoption_year|\n",
            "+-------------+\n",
            "|         2023|\n",
            "|         2022|\n",
            "|         2024|\n",
            "+-------------+\n",
            "\n",
            "+----------+\n",
            "|genai_tool|\n",
            "+----------+\n",
            "|   ChatGPT|\n",
            "|    Gemini|\n",
            "|     LLaMA|\n",
            "|    Claude|\n",
            "|      Groq|\n",
            "|   Mixtral|\n",
            "+----------+\n",
            "\n",
            "+--------------------+-------------+----------+-----------------------+--------------+-----------------------+-----------------+--------------------+\n",
            "|        company_name|adoption_year|genai_tool|productivity_change_(%)|adoption_level|training_hours_provided|new_roles_created|  employee_sentiment|\n",
            "+--------------------+-------------+----------+-----------------------+--------------+-----------------------+-----------------+--------------------+\n",
            "| Davis LLC Pvt. Ltd.|         2022|   Mixtral|                   25.2|          High|                    657|                8|productivity incr...|\n",
            "|Roberts, Holland ...|         2023|    Claude|                   27.5|          High|                  23021|               17|we now finish tas...|\n",
            "| Roman Inc Pvt. Ltd.|         2023|    Gemini|                   11.5|          High|                   4680|               17|productivity incr...|\n",
            "|Nguyen-Strickland...|         2023|      Groq|                    7.0|          High|                   1750|               12|ai helped me redu...|\n",
            "|Jackson PLC Pvt. ...|         2024|     LLaMA|                    2.5|          High|                   3925|               22|job roles have sh...|\n",
            "|Forbes Ltd Pvt. Ltd.|         2022|    Gemini|                   19.9|          High|                  11485|               16|new roles are exc...|\n",
            "|Barker, Williams ...|         2022|   Mixtral|                    6.6|           Low|                   2593|               11|job roles have sh...|\n",
            "|Wheeler, Warner a...|         2022|      Groq|                   20.4|          High|                  11692|               16|collaboration imp...|\n",
            "|Ramirez, Wells an...|         2022|    Gemini|                   29.5|          High|                  22484|                7|theres concern th...|\n",
            "|Morris Inc Pvt. Ltd.|         2022|   ChatGPT|                   33.3|        Medium|                  20689|               24|i love using aiit...|\n",
            "|Neal and Sons Pvt...|         2023|    Gemini|                   22.4|          High|                   2672|               21|job roles have sh...|\n",
            "|Russell-Brown Pvt...|         2022|    Gemini|                   12.4|          High|                  24129|               25|job roles have sh...|\n",
            "| Moore Inc Pvt. Ltd.|         2022|   Mixtral|                   28.3|          High|                  11833|               29|job roles have sh...|\n",
            "| Cantu Inc Pvt. Ltd.|         2022|    Claude|                   33.6|          High|                  18708|               13|collaboration imp...|\n",
            "|Fisher PLC Pvt. Ltd.|         2024|    Gemini|                    2.9|          High|                  10291|               13|ai helped me redu...|\n",
            "|Garcia, Watts and...|         2024|   ChatGPT|                    6.1|          High|                   4167|                1|collaboration imp...|\n",
            "|Johnson PLC Pvt. ...|         2023|   Mixtral|                   20.6|           Low|                   1574|               22|we now finish tas...|\n",
            "|Wright Inc Pvt. Ltd.|         2022|    Claude|                    9.2|          High|                  21301|               29|theres concern th...|\n",
            "|Bradley, Lewis an...|         2024|    Claude|                   10.4|          High|                  16397|               24|productivity incr...|\n",
            "|Taylor-Gonzalez P...|         2022|     LLaMA|                   25.5|          High|                   3750|               27|theres concern th...|\n",
            "+--------------------+-------------+----------+-----------------------+--------------+-----------------------+-----------------+--------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    }
  ]
}